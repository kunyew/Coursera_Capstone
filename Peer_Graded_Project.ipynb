{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Peer Graded Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d65fb2c07d914ab4b4982f0cc732becf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7bfe580435024234bdcb38fd18091215",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a6a95bc53754d809ed821c3a010179d",
              "IPY_MODEL_301e4b9a9e4b461b85efbda8ccfc2af4"
            ]
          }
        },
        "7bfe580435024234bdcb38fd18091215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a6a95bc53754d809ed821c3a010179d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c088e5fa676d4f38a88326713cb44e69",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bbe5500ad9e46edad2b9318379b8c94"
          }
        },
        "301e4b9a9e4b461b85efbda8ccfc2af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52128c09db4140cb8b6bc5bd23449f15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 44.7M/44.7M [00:00&lt;00:00, 176MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b01ab3a62ac749fe88cf9cacd4e78336"
          }
        },
        "c088e5fa676d4f38a88326713cb44e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bbe5500ad9e46edad2b9318379b8c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52128c09db4140cb8b6bc5bd23449f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b01ab3a62ac749fe88cf9cacd4e78336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunyew/Coursera_Capstone/blob/master/Peer_Graded_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1CyQnx-tZzq",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"http://cocl.us/pytorch_link_top\">\n",
        "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
        "</a> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqKUJ_pjtZzu",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDeX_RqztZzx",
        "colab_type": "text"
      },
      "source": [
        "<h1><h1>Pre-trained-Models with PyTorch </h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80uTi4oJtZz0",
        "colab_type": "text"
      },
      "source": [
        "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n",
        "<ul>\n",
        "<li>change the output layer</li>\n",
        "<li> train the model</li> \n",
        "<li>  identify  several  misclassified samples</li> \n",
        " </ul>\n",
        "You will take several screenshots of your work and share your notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T426E7FDtZz3",
        "colab_type": "text"
      },
      "source": [
        "<h2>Table of Contents</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpdKnWY7tZz6",
        "colab_type": "text"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "\n",
        "<ul>\n",
        "    <li><a href=\"#download_data\"> Download Data</a></li>\n",
        "    <li><a href=\"#auxiliary\"> Imports and Auxiliary Functions </a></li>\n",
        "    <li><a href=\"#data_class\"> Dataset Class</a></li>\n",
        "    <li><a href=\"#Question_1\">Question 1</a></li>\n",
        "    <li><a href=\"#Question_2\">Question 2</a></li>\n",
        "    <li><a href=\"#Question_3\">Question 3</a></li>\n",
        "</ul>\n",
        "<p>Estimated Time Needed: <strong>120 min</strong></p>\n",
        " </div>\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbQG610-tZz8",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"download_data\">Download Data</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lljujmKvtZz_",
        "colab_type": "text"
      },
      "source": [
        "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bj_ipPqBtZ0F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "584f684f-1c61-4bc4-bff3-33418f6d786f"
      },
      "source": [
        "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 23:35:33--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2598656062 (2.4G) [application/zip]\n",
            "Saving to: â€˜Positive_tensors.zipâ€™\n",
            "\n",
            "Positive_tensors.zi 100%[===================>]   2.42G  25.8MB/s    in 96s     \n",
            "\n",
            "2020-03-18 23:37:09 (25.9 MB/s) - â€˜Positive_tensors.zipâ€™ saved [2598656062/2598656062]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-sci3WntZ0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8dd5b150-8cc8-47d6-8d7b-5026be6f2500"
      },
      "source": [
        "!unzip -q Positive_tensors.zip "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace Positive_tensors/5114.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace Positive_tensors/17137.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRyZAZ6stZ0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "57ae553d-0e48-41f0-c3e0-d41a493d8a4a"
      },
      "source": [
        "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
        "!unzip -q Negative_tensors.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-18 23:42:52--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n",
            "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
            "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2111408108 (2.0G) [application/zip]\n",
            "Saving to: â€˜Negative_tensors.zipâ€™\n",
            "\n",
            "Negative_tensors.zi 100%[===================>]   1.97G  22.9MB/s    in 80s     \n",
            "\n",
            "2020-03-18 23:44:12 (25.1 MB/s) - â€˜Negative_tensors.zipâ€™ saved [2111408108/2111408108]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXZqekrQtZ0j",
        "colab_type": "text"
      },
      "source": [
        "We will install torchvision:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thuLYIIOtZ0l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "e6c91ef2-1a1a-4a41-db3f-319498bd844f"
      },
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnO_WK3ftZ0s",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20AzeR7ytZ0t",
        "colab_type": "text"
      },
      "source": [
        "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lpzCtTYtZ0u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0aef748d-6a20-4d8f-f0f3-1aca069b40f1"
      },
      "source": [
        "# These are the libraries will be used for this lab.\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import pandas\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import torch \n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import h5py\n",
        "import os\n",
        "import glob\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f648c75b4b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKjRr6FNtZ0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "import matplotlib.pylab as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vVkgEJdtZ05",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpRzI3GHtZ07",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"data_class\">Dataset Class</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H16qOaN-tZ09",
        "colab_type": "text"
      },
      "source": [
        " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwVDVlVQtZ0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9a2e880-dd2d-403a-ac9c-91ac0ad0be42"
      },
      "source": [
        "# Create your own dataset object\n",
        "\n",
        "class Dataset(Dataset):\n",
        "\n",
        "    # Constructor\n",
        "    def __init__(self,transform=None,train=True):\n",
        "        #directory=\"/home/dsxuser/work\"\n",
        "        directory=\"/content\"\n",
        "        positive=\"Positive_tensors\"\n",
        "        negative='Negative_tensors'\n",
        "\n",
        "        positive_file_path=os.path.join(directory,positive)\n",
        "        negative_file_path=os.path.join(directory,negative)\n",
        "        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n",
        "        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n",
        "        number_of_samples=len(positive_files)+len(negative_files)\n",
        "        self.all_files=[None]*number_of_samples\n",
        "        self.all_files[::2]=positive_files\n",
        "        self.all_files[1::2]=negative_files \n",
        "        # The transform is goint to be used on image\n",
        "        self.transform = transform\n",
        "        #torch.LongTensor\n",
        "        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n",
        "        self.Y[::2]=1\n",
        "        self.Y[1::2]=0\n",
        "        \n",
        "        if train:\n",
        "            self.all_files=self.all_files[0:30000]\n",
        "            self.Y=self.Y[0:30000]\n",
        "            self.len=len(self.all_files)\n",
        "        else:\n",
        "            self.all_files=self.all_files[30000:]\n",
        "            self.Y=self.Y[30000:]\n",
        "            self.len=len(self.all_files)     \n",
        "       \n",
        "    # Get the length\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    # Getter\n",
        "    def __getitem__(self, idx):\n",
        "               \n",
        "        image=torch.load(self.all_files[idx])\n",
        "        y=self.Y[idx]\n",
        "                  \n",
        "        # If there is any transform method, apply it onto the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, y\n",
        "    \n",
        "print(\"done\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2NQWHYx6a_E",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJw6KLuKtZ1I",
        "colab_type": "text"
      },
      "source": [
        "We create two dataset objects, one for the training data and one for the validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nja4h1kUtZ1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed4e99ba-8caa-4d48-f978-7ab0cad3211c"
      },
      "source": [
        "train_dataset = Dataset(train=True)\n",
        "validation_dataset = Dataset(train=False)\n",
        "print(\"done\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9VUSg1ktZ1N",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Question_1\">Question 1</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V7vD0NHtZ1P",
        "colab_type": "text"
      },
      "source": [
        "<b>Prepare a pre-trained resnet18 model :</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q1eC5zttZ1R",
        "colab_type": "text"
      },
      "source": [
        "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AKwyelStZ1T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "d65fb2c07d914ab4b4982f0cc732becf",
            "7bfe580435024234bdcb38fd18091215",
            "9a6a95bc53754d809ed821c3a010179d",
            "301e4b9a9e4b461b85efbda8ccfc2af4",
            "c088e5fa676d4f38a88326713cb44e69",
            "2bbe5500ad9e46edad2b9318379b8c94",
            "52128c09db4140cb8b6bc5bd23449f15",
            "b01ab3a62ac749fe88cf9cacd4e78336"
          ]
        },
        "outputId": "48bc229a-41a7-400b-83f3-3b12057f8fe8"
      },
      "source": [
        "#step 1: load the resnet18 model\n",
        "model = models.resnet18(pretrained=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d65fb2c07d914ab4b4982f0cc732becf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=46827520), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAg5aM52tZ1b",
        "colab_type": "text"
      },
      "source": [
        "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nec0jxvFtZ1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 2: Set the parameter cannot be trained for the pre-trained model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad =False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsbZSJWEtZ1j",
        "colab_type": "text"
      },
      "source": [
        "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SbE1apltZ1l",
        "colab_type": "text"
      },
      "source": [
        "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jzuyhqxtZ1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fc = nn.Linear(512,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSskUb7atZ1r",
        "colab_type": "text"
      },
      "source": [
        "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgygKenOtZ1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cec9d567-4bc4-4c9f-c903-53095c7f35ce"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sdRTPi0tZ1w",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Question_2\">Question 2: Train the Model</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9foPBxEtZ1y",
        "colab_type": "text"
      },
      "source": [
        "In this question you will train your, model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AC55HUftZ10",
        "colab_type": "text"
      },
      "source": [
        "<b>Step 1</b>: Create a cross entropy criterion function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlPjDQoVtZ13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 1: Create the loss function\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq5fxCD5tZ18",
        "colab_type": "text"
      },
      "source": [
        "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIVhOU2etZ19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader= torch.utils.data.DataLoader(dataset = train_dataset, batch_size=100)\n",
        "validation_loader = torch.utils.data.DataLoader( dataset = validation_dataset, batch_size =100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlimHxO9tZ2B",
        "colab_type": "text"
      },
      "source": [
        "<b>Step 3</b>: Use the following optimizer to minimize the loss "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAlVUm7jtZ2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LABuC_mtZ2E",
        "colab_type": "text"
      },
      "source": [
        "<!--Empty Space for separating topics-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH3OLji3tZ2F",
        "colab_type": "text"
      },
      "source": [
        "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtcXPc_BtZ2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs=1\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "correct=0\n",
        "N_test=len(validation_dataset)\n",
        "N_train=len(train_dataset)\n",
        "start_time = time.time()\n",
        "\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    loss_sublist=[] \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        model.train() \n",
        "        #clear gradient \n",
        "        optimizer.zero_grad()\n",
        "        #make a prediction \n",
        "        z = model(x)\n",
        "        # calculate loss \n",
        "        loss = loss_function(z,y)\n",
        "        loss_sublist.append(loss.data.item())  #loss_sublist contains loss for each iteration\n",
        "        # calculate gradients of parameters \n",
        "        loss.backward()\n",
        "        # update parameters \n",
        "        optimizer.step()\n",
        "    loss_list.append(np.mean(loss_sublist))    # loss_list contains loss for each epoch\n",
        "        \n",
        "    \n",
        "        \n",
        "    correct =0\n",
        "    for x_test, y_test in validation_loader:\n",
        "        # set model to eval\n",
        "        model.eval()\n",
        "        #make a prediction\n",
        "        z = model(x_test)\n",
        "        #find max \n",
        "        _,yhat = torch.max(z.data, 1)\n",
        "        correct += (yhat== y_test).sum().item()\n",
        "         \n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "            \n",
        "    accuracy=correct/N_test\n",
        "    accuracy_list.append(accuracy)\n",
        "    \n",
        "       \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KvGetCUtZ2K",
        "colab_type": "text"
      },
      "source": [
        "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5AcL1f7tZ2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2906c315-ecdb-41a5-fa8f-249fd7a9c774"
      },
      "source": [
        "print(accuracy)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMheXYeptZ2O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "18d3c6ba-e23b-403a-abab-bbced8ec0b1e"
      },
      "source": [
        "plt.plot(loss_sublist)\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.show()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCJRSKsD9f+47sZgHcLGeAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULEgPTjmtZ2R",
        "colab_type": "text"
      },
      "source": [
        "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdmQcz2VtZ2S",
        "colab_type": "text"
      },
      "source": [
        "<b>Identify the first four misclassified samples using the validation data:</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaKPOHu6tZ2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c512cbf9-2795-4e99-b0d5-1543d71b970a"
      },
      "source": [
        "misclassified_list = []\n",
        "count=0\n",
        "\n",
        "for x_test, y_test in validation_loader:\n",
        "  \n",
        "     \n",
        "    #make a prediction\n",
        "    z = model(x_test)\n",
        "    #find max \n",
        "    _,yhat = torch.max(z.data, 1)\n",
        "    if  (yhat == y_test).sum().item() != 1:\n",
        "        misclassified_list.append(x_test)\n",
        "        count += 1\n",
        "    if count >=4:\n",
        "        break\n",
        "   \n",
        "print(misclassified_list)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[[[ 0.8961,  0.8618,  0.7077,  ...,  0.8618,  0.6906,  0.5707],\n",
            "          [ 0.9132,  0.8618,  0.6906,  ...,  0.7419,  0.5878,  0.5022],\n",
            "          [ 0.9132,  0.8447,  0.6563,  ...,  0.5878,  0.5022,  0.4679],\n",
            "          ...,\n",
            "          [ 1.1529,  1.2557,  1.2043,  ...,  0.4679,  0.4679,  0.4679],\n",
            "          [ 0.9474,  1.0159,  0.9988,  ...,  0.5536,  0.5707,  0.5878],\n",
            "          [ 0.8447,  0.8618,  0.8276,  ...,  0.4851,  0.5364,  0.5878]],\n",
            "\n",
            "         [[ 1.0455,  1.0105,  0.8529,  ...,  0.9930,  0.8179,  0.6954],\n",
            "          [ 1.0630,  1.0105,  0.8354,  ...,  0.8704,  0.7129,  0.6254],\n",
            "          [ 1.0630,  0.9930,  0.8004,  ...,  0.7129,  0.6254,  0.5903],\n",
            "          ...,\n",
            "          [ 1.2906,  1.3782,  1.3256,  ...,  0.5378,  0.5378,  0.5378],\n",
            "          [ 1.0805,  1.1506,  1.1331,  ...,  0.6254,  0.6429,  0.6604],\n",
            "          [ 0.9755,  0.9930,  0.9580,  ...,  0.5553,  0.6078,  0.6604]],\n",
            "\n",
            "         [[ 1.2282,  1.1934,  1.0365,  ...,  1.1411,  0.9668,  0.8448],\n",
            "          [ 1.2457,  1.1934,  1.0191,  ...,  1.0191,  0.8622,  0.7751],\n",
            "          [ 1.2457,  1.1759,  0.9842,  ...,  0.8622,  0.7751,  0.7402],\n",
            "          ...,\n",
            "          [ 1.4897,  1.5768,  1.5245,  ...,  0.7054,  0.7054,  0.7054],\n",
            "          [ 1.2631,  1.3328,  1.3154,  ...,  0.7925,  0.8099,  0.8274],\n",
            "          [ 1.1585,  1.1759,  1.1411,  ...,  0.7228,  0.7751,  0.8274]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3755,  1.3755,  1.3755,  ...,  1.1529,  1.1529,  1.1529],\n",
            "          [ 1.3584,  1.3584,  1.3584,  ...,  1.1700,  1.1700,  1.1700],\n",
            "          [ 1.3413,  1.3413,  1.3413,  ...,  1.2043,  1.2043,  1.2043],\n",
            "          ...,\n",
            "          [ 1.1187,  1.1015,  1.1015,  ...,  1.1015,  1.1015,  1.1015],\n",
            "          [ 1.1872,  1.1529,  1.1358,  ...,  1.1015,  1.1015,  1.1015],\n",
            "          [ 1.2385,  1.2043,  1.1700,  ...,  1.1015,  1.1015,  1.1015]],\n",
            "\n",
            "         [[ 1.3081,  1.3081,  1.3081,  ...,  1.1506,  1.1506,  1.1506],\n",
            "          [ 1.2906,  1.2906,  1.2906,  ...,  1.1681,  1.1681,  1.1681],\n",
            "          [ 1.2731,  1.2731,  1.2731,  ...,  1.2031,  1.2031,  1.2031],\n",
            "          ...,\n",
            "          [ 1.1331,  1.1155,  1.1155,  ...,  1.0980,  1.0980,  1.0980],\n",
            "          [ 1.2031,  1.1681,  1.1506,  ...,  1.0980,  1.0980,  1.0980],\n",
            "          [ 1.2556,  1.2206,  1.1856,  ...,  1.0980,  1.0980,  1.0980]],\n",
            "\n",
            "         [[ 1.3677,  1.3677,  1.3677,  ...,  1.2108,  1.2108,  1.2108],\n",
            "          [ 1.3502,  1.3502,  1.3502,  ...,  1.2282,  1.2282,  1.2282],\n",
            "          [ 1.3328,  1.3328,  1.3328,  ...,  1.2631,  1.2631,  1.2631],\n",
            "          ...,\n",
            "          [ 1.1585,  1.1411,  1.1411,  ...,  1.1585,  1.1585,  1.1585],\n",
            "          [ 1.2282,  1.1934,  1.1759,  ...,  1.1585,  1.1585,  1.1585],\n",
            "          [ 1.2805,  1.2457,  1.2108,  ...,  1.1585,  1.1585,  1.1585]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0673,  1.0673,  1.0673,  ...,  1.2214,  1.2899,  1.3584],\n",
            "          [ 1.1015,  1.1187,  1.1358,  ...,  1.2214,  1.2728,  1.3242],\n",
            "          [ 1.1529,  1.1872,  1.2214,  ...,  1.2214,  1.2557,  1.3070],\n",
            "          ...,\n",
            "          [-0.9534, -0.9877, -0.9877,  ...,  1.3755,  1.3755,  1.3755],\n",
            "          [-0.9534, -0.9877, -0.9705,  ...,  1.4098,  1.4098,  1.4098],\n",
            "          [-0.9705, -0.9877, -0.9705,  ...,  1.4440,  1.4440,  1.4440]],\n",
            "\n",
            "         [[ 1.0805,  1.0805,  1.0805,  ...,  1.1681,  1.2381,  1.3081],\n",
            "          [ 1.1155,  1.1331,  1.1506,  ...,  1.1681,  1.2206,  1.2731],\n",
            "          [ 1.1681,  1.2031,  1.2381,  ...,  1.1681,  1.2031,  1.2556],\n",
            "          ...,\n",
            "          [-0.9153, -0.9503, -0.9503,  ...,  1.3957,  1.3957,  1.3957],\n",
            "          [-0.9153, -0.9503, -0.9328,  ...,  1.4307,  1.4307,  1.4307],\n",
            "          [-0.9328, -0.9503, -0.9328,  ...,  1.4657,  1.4657,  1.4657]],\n",
            "\n",
            "         [[ 1.0714,  1.0714,  1.0714,  ...,  1.1759,  1.2457,  1.3154],\n",
            "          [ 1.1062,  1.1237,  1.1411,  ...,  1.1759,  1.2282,  1.2805],\n",
            "          [ 1.1585,  1.1934,  1.2282,  ...,  1.1759,  1.2108,  1.2631],\n",
            "          ...,\n",
            "          [-0.7413, -0.7761, -0.7761,  ...,  1.4200,  1.4200,  1.4200],\n",
            "          [-0.7413, -0.7761, -0.7587,  ...,  1.4548,  1.4548,  1.4548],\n",
            "          [-0.7587, -0.7761, -0.7587,  ...,  1.4897,  1.4897,  1.4897]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.9303,  0.9303,  0.9303,  ...,  0.8104,  0.8104,  0.8276],\n",
            "          [ 0.9646,  0.9646,  0.9474,  ...,  0.7933,  0.7933,  0.7933],\n",
            "          [ 1.0159,  0.9988,  0.9646,  ...,  0.7762,  0.7591,  0.7591],\n",
            "          ...,\n",
            "          [ 1.0159,  1.0331,  1.0502,  ...,  0.8104,  0.7933,  0.7933],\n",
            "          [ 1.0159,  1.0331,  1.0502,  ...,  0.7419,  0.7419,  0.7419],\n",
            "          [ 0.9988,  1.0331,  1.0502,  ...,  0.6906,  0.6906,  0.6906]],\n",
            "\n",
            "         [[ 0.9405,  0.9405,  0.9405,  ...,  0.8179,  0.8179,  0.8354],\n",
            "          [ 0.9755,  0.9755,  0.9580,  ...,  0.8004,  0.8004,  0.8004],\n",
            "          [ 1.0280,  1.0105,  0.9755,  ...,  0.7829,  0.7654,  0.7654],\n",
            "          ...,\n",
            "          [ 1.0280,  1.0455,  1.0630,  ...,  0.8004,  0.8004,  0.8004],\n",
            "          [ 1.0280,  1.0455,  1.0630,  ...,  0.7479,  0.7479,  0.7479],\n",
            "          [ 1.0105,  1.0455,  1.0630,  ...,  0.6954,  0.6954,  0.6954]],\n",
            "\n",
            "         [[ 0.9319,  0.9319,  0.9319,  ...,  0.8448,  0.8448,  0.8622],\n",
            "          [ 0.9668,  0.9668,  0.9494,  ...,  0.8274,  0.8274,  0.8274],\n",
            "          [ 1.0191,  1.0017,  0.9668,  ...,  0.8099,  0.7925,  0.7925],\n",
            "          ...,\n",
            "          [ 1.0191,  1.0365,  1.0539,  ...,  0.8099,  0.7925,  0.7925],\n",
            "          [ 1.0191,  1.0365,  1.0539,  ...,  0.7402,  0.7402,  0.7402],\n",
            "          [ 1.0017,  1.0365,  1.0539,  ...,  0.6879,  0.6879,  0.6879]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8037,  1.8037,  1.8208,  ...,  1.5468,  1.5639,  1.5810],\n",
            "          [ 1.8037,  1.8208,  1.8208,  ...,  1.5125,  1.5297,  1.5639],\n",
            "          [ 1.8208,  1.8208,  1.8379,  ...,  1.4783,  1.4954,  1.5125],\n",
            "          ...,\n",
            "          [ 1.6838,  1.6838,  1.6838,  ...,  1.4269,  1.4783,  1.5468],\n",
            "          [ 1.6838,  1.6838,  1.6838,  ...,  1.4612,  1.5297,  1.5982],\n",
            "          [ 1.6838,  1.6838,  1.6838,  ...,  1.5125,  1.5639,  1.6324]],\n",
            "\n",
            "         [[ 1.9034,  1.9034,  1.9209,  ...,  1.6583,  1.6758,  1.6933],\n",
            "          [ 1.9034,  1.9209,  1.9209,  ...,  1.6232,  1.6408,  1.6758],\n",
            "          [ 1.9209,  1.9209,  1.9384,  ...,  1.5882,  1.6057,  1.6232],\n",
            "          ...,\n",
            "          [ 1.7808,  1.7808,  1.7808,  ...,  1.4482,  1.5007,  1.5707],\n",
            "          [ 1.7808,  1.7808,  1.7808,  ...,  1.4832,  1.5532,  1.6232],\n",
            "          [ 1.7808,  1.7808,  1.7808,  ...,  1.5357,  1.5882,  1.6583]],\n",
            "\n",
            "         [[ 1.9080,  1.9080,  1.9254,  ...,  1.7860,  1.8034,  1.8208],\n",
            "          [ 1.9080,  1.9254,  1.9254,  ...,  1.7511,  1.7685,  1.8034],\n",
            "          [ 1.9254,  1.9254,  1.9428,  ...,  1.7163,  1.7337,  1.7511],\n",
            "          ...,\n",
            "          [ 1.7860,  1.7860,  1.7860,  ...,  1.4722,  1.5245,  1.5942],\n",
            "          [ 1.7860,  1.7860,  1.7860,  ...,  1.5071,  1.5768,  1.6465],\n",
            "          [ 1.7860,  1.7860,  1.7860,  ...,  1.5594,  1.6117,  1.6814]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4440,  1.4612,  1.4954,  ...,  1.3242,  1.3070,  1.2899],\n",
            "          [ 1.4783,  1.4954,  1.5125,  ...,  1.3242,  1.3070,  1.2899],\n",
            "          [ 1.5125,  1.5297,  1.5297,  ...,  1.3070,  1.2899,  1.2728],\n",
            "          ...,\n",
            "          [ 1.3242,  1.3755,  1.4269,  ...,  1.4612,  1.4440,  1.4269],\n",
            "          [ 1.3070,  1.3584,  1.4098,  ...,  1.4612,  1.4440,  1.4269],\n",
            "          [ 1.2899,  1.3413,  1.3755,  ...,  1.4612,  1.4440,  1.4269]],\n",
            "\n",
            "         [[ 1.3957,  1.4132,  1.4482,  ...,  1.3081,  1.2906,  1.2731],\n",
            "          [ 1.4307,  1.4482,  1.4657,  ...,  1.3081,  1.2906,  1.2731],\n",
            "          [ 1.4657,  1.4832,  1.4832,  ...,  1.2906,  1.2731,  1.2556],\n",
            "          ...,\n",
            "          [ 1.3081,  1.3606,  1.4132,  ...,  1.4132,  1.3957,  1.3782],\n",
            "          [ 1.2906,  1.3431,  1.3957,  ...,  1.4132,  1.3957,  1.3782],\n",
            "          [ 1.2731,  1.3256,  1.3606,  ...,  1.4132,  1.3957,  1.3782]],\n",
            "\n",
            "         [[ 1.3677,  1.3851,  1.4200,  ...,  1.3154,  1.2980,  1.2805],\n",
            "          [ 1.4025,  1.4200,  1.4374,  ...,  1.3154,  1.2980,  1.2805],\n",
            "          [ 1.4374,  1.4548,  1.4548,  ...,  1.2980,  1.2805,  1.2631],\n",
            "          ...,\n",
            "          [ 1.3154,  1.3677,  1.4200,  ...,  1.3851,  1.3677,  1.3502],\n",
            "          [ 1.2980,  1.3502,  1.4025,  ...,  1.3851,  1.3677,  1.3502],\n",
            "          [ 1.2805,  1.3328,  1.3677,  ...,  1.3851,  1.3677,  1.3502]]]]), tensor([[[[ 1.3070,  1.2214,  1.1872,  ..., -0.9705, -0.9705, -0.9705],\n",
            "          [ 1.4440,  1.3584,  1.2728,  ..., -1.0390, -1.0562, -1.0904],\n",
            "          [ 1.5810,  1.4612,  1.3413,  ..., -0.9877, -1.0562, -1.1075],\n",
            "          ...,\n",
            "          [ 1.4783,  1.4954,  1.5297,  ...,  1.2214,  1.2043,  1.1872],\n",
            "          [ 1.4783,  1.4954,  1.5297,  ...,  1.2214,  1.2043,  1.1872],\n",
            "          [ 1.4954,  1.4954,  1.5125,  ...,  1.2214,  1.2214,  1.2043]],\n",
            "\n",
            "         [[ 1.3957,  1.3081,  1.2731,  ..., -0.8627, -0.8627, -0.8627],\n",
            "          [ 1.5357,  1.4482,  1.3606,  ..., -0.9328, -0.9503, -0.9853],\n",
            "          [ 1.6758,  1.5532,  1.4307,  ..., -0.8803, -0.9503, -1.0028],\n",
            "          ...,\n",
            "          [ 1.5882,  1.6057,  1.6408,  ...,  1.3606,  1.3431,  1.3256],\n",
            "          [ 1.5882,  1.6057,  1.6408,  ...,  1.3606,  1.3431,  1.3256],\n",
            "          [ 1.6057,  1.6057,  1.6232,  ...,  1.3606,  1.3606,  1.3431]],\n",
            "\n",
            "         [[ 1.5594,  1.4722,  1.4374,  ..., -0.6018, -0.6018, -0.6018],\n",
            "          [ 1.6988,  1.6117,  1.5245,  ..., -0.6715, -0.6890, -0.7238],\n",
            "          [ 1.8383,  1.7163,  1.5942,  ..., -0.6193, -0.6890, -0.7413],\n",
            "          ...,\n",
            "          [ 1.7163,  1.7337,  1.7685,  ...,  1.4897,  1.4722,  1.4548],\n",
            "          [ 1.7163,  1.7337,  1.7685,  ...,  1.4897,  1.4722,  1.4548],\n",
            "          [ 1.7337,  1.7337,  1.7511,  ...,  1.4897,  1.4897,  1.4722]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1187,  1.1187,  1.1187,  ...,  0.9303,  0.9303,  0.9303],\n",
            "          [ 1.1358,  1.1358,  1.1358,  ...,  0.8961,  0.8961,  0.8961],\n",
            "          [ 1.1358,  1.1358,  1.1358,  ...,  0.8789,  0.8789,  0.8789],\n",
            "          ...,\n",
            "          [ 0.7591,  0.7933,  0.8618,  ...,  0.6734,  0.6563,  0.6392],\n",
            "          [ 0.7591,  0.7933,  0.8618,  ...,  0.6734,  0.6563,  0.6392],\n",
            "          [ 0.7591,  0.7933,  0.8618,  ...,  0.6734,  0.6563,  0.6392]],\n",
            "\n",
            "         [[ 0.9055,  0.9055,  0.9055,  ...,  0.1352,  0.1352,  0.1352],\n",
            "          [ 0.9230,  0.9230,  0.9230,  ...,  0.1001,  0.1001,  0.1001],\n",
            "          [ 0.9230,  0.9230,  0.9230,  ...,  0.0826,  0.0826,  0.0826],\n",
            "          ...,\n",
            "          [ 0.7479,  0.7829,  0.8529,  ..., -0.0399, -0.0574, -0.0749],\n",
            "          [ 0.7479,  0.7829,  0.8529,  ..., -0.0399, -0.0574, -0.0749],\n",
            "          [ 0.7479,  0.7829,  0.8529,  ..., -0.0399, -0.0574, -0.0749]],\n",
            "\n",
            "         [[ 0.7925,  0.7925,  0.7925,  ..., -0.3055, -0.3055, -0.3055],\n",
            "          [ 0.8099,  0.8099,  0.8099,  ..., -0.3404, -0.3404, -0.3404],\n",
            "          [ 0.8099,  0.8099,  0.8099,  ..., -0.3578, -0.3578, -0.3578],\n",
            "          ...,\n",
            "          [ 0.6705,  0.7054,  0.7751,  ..., -0.3753, -0.3927, -0.4101],\n",
            "          [ 0.6705,  0.7054,  0.7751,  ..., -0.3753, -0.3927, -0.4101],\n",
            "          [ 0.6705,  0.7054,  0.7751,  ..., -0.3753, -0.3927, -0.4101]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2899,  1.2557,  1.2385,  ...,  1.3584,  1.3584,  1.3755],\n",
            "          [ 1.3070,  1.2728,  1.2557,  ...,  1.3927,  1.3927,  1.4098],\n",
            "          [ 1.3413,  1.3070,  1.2728,  ...,  1.4440,  1.4440,  1.4440],\n",
            "          ...,\n",
            "          [-0.6452, -0.6452, -0.6452,  ...,  1.2728,  1.2899,  1.3070],\n",
            "          [-0.6452, -0.6452, -0.6452,  ...,  1.3070,  1.3242,  1.3413],\n",
            "          [-0.6623, -0.6452, -0.6452,  ...,  1.3413,  1.3584,  1.3755]],\n",
            "\n",
            "         [[ 1.3606,  1.3256,  1.3081,  ...,  1.4307,  1.4307,  1.4482],\n",
            "          [ 1.3782,  1.3431,  1.3256,  ...,  1.4657,  1.4657,  1.4832],\n",
            "          [ 1.4132,  1.3782,  1.3431,  ...,  1.5182,  1.5182,  1.5182],\n",
            "          ...,\n",
            "          [-0.6001, -0.6001, -0.5826,  ...,  1.3431,  1.3606,  1.3782],\n",
            "          [-0.6001, -0.6001, -0.6001,  ...,  1.3782,  1.3957,  1.4132],\n",
            "          [-0.6176, -0.6001, -0.6001,  ...,  1.4132,  1.4307,  1.4482]],\n",
            "\n",
            "         [[ 1.4722,  1.4374,  1.4200,  ...,  1.5420,  1.5420,  1.5594],\n",
            "          [ 1.4897,  1.4548,  1.4374,  ...,  1.5768,  1.5768,  1.5942],\n",
            "          [ 1.5245,  1.4897,  1.4548,  ...,  1.6291,  1.6291,  1.6291],\n",
            "          ...,\n",
            "          [-0.4275, -0.4275, -0.4275,  ...,  1.4897,  1.5071,  1.5245],\n",
            "          [-0.4275, -0.4275, -0.4275,  ...,  1.5245,  1.5420,  1.5594],\n",
            "          [-0.4450, -0.4275, -0.4275,  ...,  1.5594,  1.5768,  1.5942]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3413,  1.3413,  1.3413,  ...,  1.4612,  1.4612,  1.4612],\n",
            "          [ 1.3242,  1.3242,  1.3242,  ...,  1.4783,  1.4783,  1.4783],\n",
            "          [ 1.3070,  1.3242,  1.3242,  ...,  1.4783,  1.4783,  1.4783],\n",
            "          ...,\n",
            "          [ 1.1872,  1.1700,  1.1529,  ...,  1.2899,  1.2385,  1.1872],\n",
            "          [ 1.2214,  1.1872,  1.1700,  ...,  1.2899,  1.2385,  1.1872],\n",
            "          [ 1.2385,  1.2043,  1.1872,  ...,  1.2899,  1.2557,  1.2043]],\n",
            "\n",
            "         [[ 1.4307,  1.4307,  1.4307,  ...,  1.5882,  1.5882,  1.5882],\n",
            "          [ 1.4132,  1.4132,  1.4132,  ...,  1.6057,  1.6057,  1.6057],\n",
            "          [ 1.3957,  1.4132,  1.4132,  ...,  1.6057,  1.6057,  1.6057],\n",
            "          ...,\n",
            "          [ 1.2731,  1.2556,  1.2381,  ...,  1.3782,  1.3256,  1.2731],\n",
            "          [ 1.3081,  1.2731,  1.2556,  ...,  1.3782,  1.3256,  1.2731],\n",
            "          [ 1.3256,  1.2906,  1.2731,  ...,  1.3782,  1.3431,  1.2906]],\n",
            "\n",
            "         [[ 1.4374,  1.4374,  1.4374,  ...,  1.5768,  1.5768,  1.5768],\n",
            "          [ 1.4200,  1.4200,  1.4200,  ...,  1.5942,  1.5942,  1.5942],\n",
            "          [ 1.4025,  1.4200,  1.4200,  ...,  1.5942,  1.5942,  1.5942],\n",
            "          ...,\n",
            "          [ 1.2805,  1.2631,  1.2457,  ...,  1.4025,  1.3502,  1.2980],\n",
            "          [ 1.3154,  1.2805,  1.2631,  ...,  1.4025,  1.3502,  1.2980],\n",
            "          [ 1.3328,  1.2980,  1.2805,  ...,  1.4025,  1.3677,  1.3154]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9474,  0.9303,  0.9132,  ...,  1.1015,  1.1015,  1.1015],\n",
            "          [ 0.9817,  0.9817,  0.9646,  ...,  0.9817,  0.9817,  0.9817],\n",
            "          [ 1.0331,  1.0331,  1.0159,  ...,  0.8789,  0.8789,  0.8789],\n",
            "          ...,\n",
            "          [ 0.0569,  0.1254,  0.1597,  ...,  0.9474,  1.0673,  1.1358],\n",
            "          [ 0.0569,  0.1426,  0.1768,  ...,  0.7077,  0.8618,  0.9474],\n",
            "          [ 0.0912,  0.1597,  0.1939,  ...,  0.4851,  0.6563,  0.7762]],\n",
            "\n",
            "         [[ 0.9580,  0.9405,  0.9230,  ...,  1.1155,  1.1155,  1.1155],\n",
            "          [ 0.9930,  0.9930,  0.9755,  ...,  0.9930,  0.9930,  0.9930],\n",
            "          [ 1.0455,  1.0455,  1.0280,  ...,  0.8880,  0.8880,  0.8880],\n",
            "          ...,\n",
            "          [-0.0224,  0.0476,  0.0826,  ...,  0.9580,  1.0805,  1.1506],\n",
            "          [-0.0224,  0.0651,  0.1001,  ...,  0.7129,  0.8704,  0.9580],\n",
            "          [ 0.0126,  0.0826,  0.1176,  ...,  0.4853,  0.6604,  0.7829]],\n",
            "\n",
            "         [[ 0.9842,  0.9668,  0.9494,  ...,  1.1411,  1.1411,  1.1411],\n",
            "          [ 1.0191,  1.0191,  1.0017,  ...,  1.0191,  1.0191,  1.0191],\n",
            "          [ 1.0714,  1.0714,  1.0539,  ...,  0.9145,  0.9145,  0.9145],\n",
            "          ...,\n",
            "          [-0.0092,  0.0605,  0.0953,  ...,  0.9494,  1.0714,  1.1411],\n",
            "          [-0.0092,  0.0779,  0.1128,  ...,  0.7054,  0.8622,  0.9494],\n",
            "          [ 0.0256,  0.0953,  0.1302,  ...,  0.4788,  0.6531,  0.7751]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4098,  1.4098,  1.4098,  ...,  1.5468,  1.5297,  1.4954],\n",
            "          [ 1.4783,  1.4612,  1.4440,  ...,  1.5125,  1.5125,  1.4783],\n",
            "          [ 1.5297,  1.5297,  1.4954,  ...,  1.4954,  1.4783,  1.4612],\n",
            "          ...,\n",
            "          [ 1.0844,  1.1358,  1.1700,  ...,  1.2043,  1.2043,  1.2043],\n",
            "          [ 1.1187,  1.1529,  1.1872,  ...,  1.2043,  1.2043,  1.2043],\n",
            "          [ 1.1358,  1.1872,  1.2043,  ...,  1.2043,  1.2043,  1.2043]],\n",
            "\n",
            "         [[ 1.4132,  1.4132,  1.4132,  ...,  1.5707,  1.5532,  1.5182],\n",
            "          [ 1.4832,  1.4657,  1.4482,  ...,  1.5357,  1.5357,  1.5007],\n",
            "          [ 1.5357,  1.5357,  1.5007,  ...,  1.5182,  1.5007,  1.4832],\n",
            "          ...,\n",
            "          [ 1.0805,  1.1331,  1.1681,  ...,  1.2206,  1.2206,  1.2206],\n",
            "          [ 1.1155,  1.1506,  1.1856,  ...,  1.2206,  1.2206,  1.2206],\n",
            "          [ 1.1331,  1.1856,  1.2031,  ...,  1.2206,  1.2206,  1.2206]],\n",
            "\n",
            "         [[ 1.4722,  1.4722,  1.4722,  ...,  1.5942,  1.5768,  1.5420],\n",
            "          [ 1.5420,  1.5245,  1.5071,  ...,  1.5594,  1.5594,  1.5245],\n",
            "          [ 1.5942,  1.5942,  1.5594,  ...,  1.5420,  1.5245,  1.5071],\n",
            "          ...,\n",
            "          [ 1.1411,  1.1934,  1.2282,  ...,  1.2457,  1.2457,  1.2457],\n",
            "          [ 1.1759,  1.2108,  1.2457,  ...,  1.2457,  1.2457,  1.2457],\n",
            "          [ 1.1934,  1.2457,  1.2631,  ...,  1.2457,  1.2457,  1.2457]]]]), tensor([[[[1.2557, 1.2899, 1.3242,  ..., 1.1529, 1.1358, 1.1358],\n",
            "          [1.2214, 1.2385, 1.2728,  ..., 1.1358, 1.1358, 1.1187],\n",
            "          [1.1872, 1.1872, 1.1872,  ..., 1.1187, 1.1187, 1.1187],\n",
            "          ...,\n",
            "          [1.3584, 1.3755, 1.3927,  ..., 1.2728, 1.2728, 1.2728],\n",
            "          [1.3413, 1.3584, 1.3755,  ..., 1.2728, 1.2728, 1.2728],\n",
            "          [1.3242, 1.3413, 1.3413,  ..., 1.2728, 1.2728, 1.2728]],\n",
            "\n",
            "         [[1.3431, 1.3782, 1.4132,  ..., 1.2556, 1.2381, 1.2381],\n",
            "          [1.3081, 1.3256, 1.3606,  ..., 1.2381, 1.2381, 1.2206],\n",
            "          [1.2731, 1.2731, 1.2731,  ..., 1.2206, 1.2206, 1.2206],\n",
            "          ...,\n",
            "          [1.4482, 1.4657, 1.4832,  ..., 1.3606, 1.3606, 1.3606],\n",
            "          [1.4307, 1.4482, 1.4657,  ..., 1.3606, 1.3606, 1.3606],\n",
            "          [1.4132, 1.4307, 1.4307,  ..., 1.3606, 1.3606, 1.3606]],\n",
            "\n",
            "         [[1.3677, 1.4025, 1.4374,  ..., 1.3502, 1.3328, 1.3328],\n",
            "          [1.3328, 1.3502, 1.3851,  ..., 1.3328, 1.3328, 1.3154],\n",
            "          [1.2980, 1.2980, 1.2980,  ..., 1.3154, 1.3154, 1.3154],\n",
            "          ...,\n",
            "          [1.4722, 1.4897, 1.5071,  ..., 1.3851, 1.3851, 1.3851],\n",
            "          [1.4548, 1.4722, 1.4897,  ..., 1.3851, 1.3851, 1.3851],\n",
            "          [1.4374, 1.4548, 1.4548,  ..., 1.3851, 1.3851, 1.3851]]],\n",
            "\n",
            "\n",
            "        [[[1.2214, 1.2043, 1.1700,  ..., 0.5536, 0.5707, 0.5707],\n",
            "          [1.1529, 1.1358, 1.1358,  ..., 0.5536, 0.5536, 0.5707],\n",
            "          [1.0673, 1.0673, 1.0673,  ..., 0.4679, 0.4851, 0.4851],\n",
            "          ...,\n",
            "          [0.9817, 1.0502, 1.0844,  ..., 0.7248, 0.7762, 0.8276],\n",
            "          [1.0159, 1.0673, 1.1015,  ..., 0.7591, 0.8104, 0.8618],\n",
            "          [1.0673, 1.1015, 1.1015,  ..., 0.7933, 0.8447, 0.8961]],\n",
            "\n",
            "         [[1.1506, 1.1331, 1.0980,  ..., 0.5203, 0.5378, 0.5378],\n",
            "          [1.0805, 1.0630, 1.0630,  ..., 0.5203, 0.5203, 0.5378],\n",
            "          [0.9930, 0.9930, 0.9930,  ..., 0.4328, 0.4503, 0.4503],\n",
            "          ...,\n",
            "          [0.9580, 1.0280, 1.0630,  ..., 0.6954, 0.7479, 0.8004],\n",
            "          [0.9930, 1.0455, 1.0805,  ..., 0.7304, 0.7829, 0.8354],\n",
            "          [1.0455, 1.0805, 1.0805,  ..., 0.7654, 0.8179, 0.8704]],\n",
            "\n",
            "         [[1.2108, 1.1934, 1.1585,  ..., 0.5659, 0.5834, 0.5834],\n",
            "          [1.1411, 1.1237, 1.1237,  ..., 0.5659, 0.5659, 0.5834],\n",
            "          [1.0539, 1.0539, 1.0539,  ..., 0.4788, 0.4962, 0.4962],\n",
            "          ...,\n",
            "          [0.9668, 1.0365, 1.0714,  ..., 0.7576, 0.8099, 0.8622],\n",
            "          [1.0017, 1.0539, 1.0888,  ..., 0.7925, 0.8448, 0.8971],\n",
            "          [1.0539, 1.0888, 1.0888,  ..., 0.8274, 0.8797, 0.9319]]],\n",
            "\n",
            "\n",
            "        [[[0.9817, 0.9988, 1.0331,  ..., 0.9474, 0.9474, 0.9474],\n",
            "          [1.0159, 1.0331, 1.0331,  ..., 0.9303, 0.9303, 0.9303],\n",
            "          [1.0502, 1.0331, 1.0159,  ..., 0.9132, 0.9132, 0.9132],\n",
            "          ...,\n",
            "          [0.8618, 0.8961, 0.9474,  ..., 0.6392, 0.6734, 0.7248],\n",
            "          [0.8276, 0.8618, 0.9132,  ..., 0.6221, 0.6734, 0.7248],\n",
            "          [0.7762, 0.8104, 0.8618,  ..., 0.6221, 0.6734, 0.7248]],\n",
            "\n",
            "         [[0.9055, 0.9230, 0.9580,  ..., 0.9230, 0.9230, 0.9230],\n",
            "          [0.9405, 0.9580, 0.9580,  ..., 0.9055, 0.9055, 0.9055],\n",
            "          [0.9755, 0.9580, 0.9405,  ..., 0.8880, 0.8880, 0.8880],\n",
            "          ...,\n",
            "          [0.8004, 0.8354, 0.8880,  ..., 0.5553, 0.5903, 0.6429],\n",
            "          [0.7654, 0.8004, 0.8529,  ..., 0.5378, 0.5903, 0.6429],\n",
            "          [0.7129, 0.7479, 0.8004,  ..., 0.5378, 0.5903, 0.6429]],\n",
            "\n",
            "         [[0.9668, 0.9842, 1.0191,  ..., 0.9842, 0.9842, 0.9842],\n",
            "          [1.0017, 1.0191, 1.0191,  ..., 0.9668, 0.9668, 0.9668],\n",
            "          [1.0365, 1.0191, 1.0017,  ..., 0.9494, 0.9494, 0.9494],\n",
            "          ...,\n",
            "          [0.8099, 0.8448, 0.8971,  ..., 0.6182, 0.6531, 0.7054],\n",
            "          [0.7751, 0.8099, 0.8622,  ..., 0.6008, 0.6531, 0.7054],\n",
            "          [0.7228, 0.7576, 0.8099,  ..., 0.6008, 0.6531, 0.7054]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[1.1187, 1.1187, 0.9646,  ..., 1.3413, 1.3413, 1.3584],\n",
            "          [1.1015, 1.1015, 0.9988,  ..., 1.3070, 1.3070, 1.3070],\n",
            "          [1.1358, 1.0502, 1.0502,  ..., 1.3927, 1.3755, 1.3413],\n",
            "          ...,\n",
            "          [1.4269, 1.4098, 1.1187,  ..., 1.3927, 1.2214, 0.9988],\n",
            "          [1.4269, 1.4098, 1.1015,  ..., 1.3927, 1.4612, 1.4269],\n",
            "          [1.4269, 1.4098, 1.1015,  ..., 1.2899, 1.5125, 1.7180]],\n",
            "\n",
            "         [[1.1155, 1.1155, 0.9755,  ..., 1.4832, 1.4832, 1.5007],\n",
            "          [1.0980, 1.0980, 1.0455,  ..., 1.4482, 1.4482, 1.4482],\n",
            "          [1.1331, 1.0980, 1.0980,  ..., 1.5357, 1.5182, 1.4832],\n",
            "          ...,\n",
            "          [1.5707, 1.5532, 1.2556,  ..., 1.5357, 1.3606, 1.1331],\n",
            "          [1.5707, 1.5532, 1.2381,  ..., 1.5357, 1.6057, 1.5707],\n",
            "          [1.5707, 1.5532, 1.2381,  ..., 1.4307, 1.6583, 1.8683]],\n",
            "\n",
            "         [[1.3502, 1.3502, 1.1934,  ..., 1.6640, 1.6640, 1.6814],\n",
            "          [1.3328, 1.3328, 1.2631,  ..., 1.6291, 1.6291, 1.6291],\n",
            "          [1.3677, 1.3154, 1.3154,  ..., 1.7163, 1.6988, 1.6640],\n",
            "          ...,\n",
            "          [1.7511, 1.7337, 1.4374,  ..., 1.7163, 1.5420, 1.3154],\n",
            "          [1.7511, 1.7337, 1.4200,  ..., 1.7337, 1.7860, 1.7511],\n",
            "          [1.7511, 1.7337, 1.4200,  ..., 1.6117, 1.8383, 2.0474]]],\n",
            "\n",
            "\n",
            "        [[[1.0673, 1.0673, 1.0844,  ..., 1.2385, 1.1529, 1.0673],\n",
            "          [1.0844, 1.0673, 1.0673,  ..., 1.2728, 1.2043, 1.1529],\n",
            "          [1.1187, 1.0844, 1.0502,  ..., 1.2214, 1.1872, 1.1529],\n",
            "          ...,\n",
            "          [1.4612, 1.4440, 1.4269,  ..., 0.5022, 0.5536, 0.5878],\n",
            "          [1.4612, 1.4440, 1.4269,  ..., 0.5878, 0.6392, 0.6734],\n",
            "          [1.4612, 1.4440, 1.4269,  ..., 0.6392, 0.6906, 0.7248]],\n",
            "\n",
            "         [[1.0455, 1.0455, 1.0630,  ..., 1.2381, 1.1506, 1.0630],\n",
            "          [1.0630, 1.0455, 1.0455,  ..., 1.2731, 1.2031, 1.1506],\n",
            "          [1.0980, 1.0630, 1.0280,  ..., 1.2206, 1.1856, 1.1506],\n",
            "          ...,\n",
            "          [1.4482, 1.4307, 1.4132,  ..., 0.5728, 0.6254, 0.6604],\n",
            "          [1.4482, 1.4307, 1.4132,  ..., 0.6604, 0.7129, 0.7479],\n",
            "          [1.4482, 1.4307, 1.4132,  ..., 0.7129, 0.7654, 0.8004]],\n",
            "\n",
            "         [[1.0888, 1.0888, 1.1062,  ..., 1.3677, 1.2805, 1.1934],\n",
            "          [1.1062, 1.0888, 1.0888,  ..., 1.4025, 1.3328, 1.2805],\n",
            "          [1.1411, 1.1062, 1.0714,  ..., 1.3502, 1.3154, 1.2805],\n",
            "          ...,\n",
            "          [1.4897, 1.4722, 1.4548,  ..., 0.7402, 0.7925, 0.8274],\n",
            "          [1.4897, 1.4722, 1.4548,  ..., 0.8274, 0.8797, 0.9145],\n",
            "          [1.4897, 1.4722, 1.4548,  ..., 0.8797, 0.9319, 0.9668]]],\n",
            "\n",
            "\n",
            "        [[[0.9132, 0.9474, 0.9988,  ..., 1.0673, 1.0844, 1.1015],\n",
            "          [0.9303, 0.9646, 0.9988,  ..., 1.0673, 1.0844, 1.1187],\n",
            "          [0.9646, 0.9817, 0.9988,  ..., 1.0502, 1.0673, 1.0844],\n",
            "          ...,\n",
            "          [0.9303, 0.8276, 0.7933,  ..., 0.8618, 0.8618, 0.8618],\n",
            "          [0.9303, 0.8276, 0.7933,  ..., 0.7248, 0.7248, 0.7248],\n",
            "          [0.9303, 0.8276, 0.7933,  ..., 0.6221, 0.6221, 0.6221]],\n",
            "\n",
            "         [[0.8880, 0.9230, 0.9755,  ..., 1.0805, 1.0980, 1.1155],\n",
            "          [0.9055, 0.9405, 0.9755,  ..., 1.0805, 1.0980, 1.1331],\n",
            "          [0.9405, 0.9580, 0.9755,  ..., 1.0455, 1.0630, 1.0805],\n",
            "          ...,\n",
            "          [0.9055, 0.8004, 0.7654,  ..., 0.8704, 0.8704, 0.8704],\n",
            "          [0.9055, 0.8004, 0.7654,  ..., 0.7304, 0.7304, 0.7304],\n",
            "          [0.9055, 0.8004, 0.7654,  ..., 0.6254, 0.6254, 0.6254]],\n",
            "\n",
            "         [[0.8971, 0.9319, 0.9842,  ..., 0.9668, 0.9842, 1.0017],\n",
            "          [0.9145, 0.9494, 0.9842,  ..., 0.9668, 0.9842, 1.0191],\n",
            "          [0.9494, 0.9668, 0.9842,  ..., 0.9668, 0.9842, 1.0017],\n",
            "          ...,\n",
            "          [0.9145, 0.8099, 0.7751,  ..., 0.8622, 0.8622, 0.8622],\n",
            "          [0.9145, 0.8099, 0.7751,  ..., 0.7228, 0.7228, 0.7228],\n",
            "          [0.9145, 0.8099, 0.7751,  ..., 0.6182, 0.6182, 0.6182]]]]), tensor([[[[ 0.6049,  0.6221,  0.6734,  ...,  0.8618,  0.8789,  0.8961],\n",
            "          [ 0.6563,  0.6563,  0.6906,  ...,  0.8447,  0.8447,  0.8618],\n",
            "          [ 0.7248,  0.7077,  0.7419,  ...,  0.8447,  0.8618,  0.8789],\n",
            "          ...,\n",
            "          [-0.3541, -0.5938, -0.6623,  ...,  0.9474,  0.9817,  0.9988],\n",
            "          [-0.4739, -0.7137, -0.7822,  ...,  0.9646,  0.9817,  0.9988],\n",
            "          [-0.5938, -0.8678, -0.9192,  ...,  0.9817,  0.9817,  0.9988]],\n",
            "\n",
            "         [[ 0.7129,  0.7304,  0.7829,  ...,  0.9755,  0.9930,  1.0105],\n",
            "          [ 0.7654,  0.7654,  0.8004,  ...,  0.9580,  0.9580,  0.9755],\n",
            "          [ 0.8354,  0.8179,  0.8529,  ...,  0.9580,  0.9755,  0.9930],\n",
            "          ...,\n",
            "          [-0.2325, -0.4776, -0.5476,  ...,  1.0280,  1.0630,  1.0805],\n",
            "          [-0.3550, -0.6001, -0.6702,  ...,  1.0455,  1.0630,  1.0805],\n",
            "          [-0.4776, -0.7577, -0.8102,  ...,  1.0630,  1.0630,  1.0805]],\n",
            "\n",
            "         [[ 0.7054,  0.7228,  0.7751,  ...,  0.9668,  0.9842,  1.0017],\n",
            "          [ 0.7576,  0.7576,  0.7925,  ...,  0.9494,  0.9494,  0.9668],\n",
            "          [ 0.8274,  0.8099,  0.8448,  ...,  0.9494,  0.9668,  0.9842],\n",
            "          ...,\n",
            "          [-0.1487, -0.3927, -0.4624,  ...,  1.0365,  1.0714,  1.0888],\n",
            "          [-0.2707, -0.5147, -0.5844,  ...,  1.0539,  1.0714,  1.0888],\n",
            "          [-0.3927, -0.6715, -0.7238,  ...,  1.0714,  1.0714,  1.0888]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5297,  1.5639,  1.6153,  ...,  1.7009,  1.7009,  1.6838],\n",
            "          [ 1.6324,  1.6495,  1.6667,  ...,  1.7009,  1.6838,  1.6667],\n",
            "          [ 1.6838,  1.7009,  1.7009,  ...,  1.6838,  1.6667,  1.6495],\n",
            "          ...,\n",
            "          [ 1.5297,  1.5125,  1.4783,  ...,  1.4098,  1.4269,  1.4440],\n",
            "          [ 1.5297,  1.4954,  1.4783,  ...,  1.4269,  1.4269,  1.4440],\n",
            "          [ 1.5297,  1.4954,  1.4612,  ...,  1.4440,  1.4612,  1.4783]],\n",
            "\n",
            "         [[ 1.5357,  1.5707,  1.6232,  ...,  1.7983,  1.7983,  1.7808],\n",
            "          [ 1.6408,  1.6583,  1.6758,  ...,  1.7983,  1.7808,  1.7633],\n",
            "          [ 1.6933,  1.7108,  1.7108,  ...,  1.7808,  1.7633,  1.7458],\n",
            "          ...,\n",
            "          [ 1.6232,  1.6057,  1.5707,  ...,  1.4132,  1.4307,  1.4482],\n",
            "          [ 1.6232,  1.5882,  1.5707,  ...,  1.4307,  1.4307,  1.4482],\n",
            "          [ 1.6232,  1.5882,  1.5532,  ...,  1.4482,  1.4657,  1.4832]],\n",
            "\n",
            "         [[ 1.5942,  1.6291,  1.6814,  ...,  1.8034,  1.8034,  1.7860],\n",
            "          [ 1.6988,  1.7163,  1.7337,  ...,  1.8034,  1.7860,  1.7685],\n",
            "          [ 1.7511,  1.7685,  1.7685,  ...,  1.7860,  1.7685,  1.7511],\n",
            "          ...,\n",
            "          [ 1.6291,  1.6117,  1.5768,  ...,  1.4722,  1.4897,  1.5071],\n",
            "          [ 1.6291,  1.5942,  1.5768,  ...,  1.4897,  1.4897,  1.5071],\n",
            "          [ 1.6291,  1.5942,  1.5594,  ...,  1.5071,  1.5245,  1.5420]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5193,  0.5878,  0.7077,  ...,  0.4679,  0.4851,  0.5022],\n",
            "          [ 0.6734,  0.7248,  0.8276,  ...,  0.4508,  0.4508,  0.4508],\n",
            "          [ 0.8104,  0.8276,  0.8961,  ...,  0.4337,  0.4337,  0.4166],\n",
            "          ...,\n",
            "          [ 0.5707,  0.5193,  0.4679,  ...,  0.4851,  0.4679,  0.4508],\n",
            "          [ 0.5536,  0.5022,  0.4679,  ...,  0.4679,  0.4679,  0.4508],\n",
            "          [ 0.5193,  0.5022,  0.4851,  ...,  0.4508,  0.4337,  0.4166]],\n",
            "\n",
            "         [[ 0.6779,  0.7304,  0.8529,  ...,  0.5553,  0.5728,  0.5903],\n",
            "          [ 0.8179,  0.8704,  0.9755,  ...,  0.5378,  0.5378,  0.5378],\n",
            "          [ 0.9580,  0.9755,  1.0455,  ...,  0.5203,  0.5203,  0.5028],\n",
            "          ...,\n",
            "          [ 0.6604,  0.6078,  0.5553,  ...,  0.5378,  0.5203,  0.5028],\n",
            "          [ 0.6429,  0.5903,  0.5553,  ...,  0.5203,  0.5203,  0.5028],\n",
            "          [ 0.6078,  0.5903,  0.5728,  ...,  0.5028,  0.4853,  0.4678]],\n",
            "\n",
            "         [[ 0.6531,  0.7402,  0.8622,  ...,  0.6531,  0.6705,  0.6879],\n",
            "          [ 0.8274,  0.8797,  0.9842,  ...,  0.6356,  0.6356,  0.6356],\n",
            "          [ 0.9668,  0.9842,  1.0539,  ...,  0.6182,  0.6182,  0.6008],\n",
            "          ...,\n",
            "          [ 0.7576,  0.7054,  0.6531,  ...,  0.6531,  0.6356,  0.6182],\n",
            "          [ 0.7402,  0.6879,  0.6531,  ...,  0.6356,  0.6356,  0.6182],\n",
            "          [ 0.7054,  0.6879,  0.6705,  ...,  0.6182,  0.6008,  0.5834]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1939,  0.2111,  0.2453,  ...,  0.2453,  0.2624,  0.2796],\n",
            "          [ 0.2282,  0.2282,  0.2111,  ...,  0.2453,  0.2624,  0.2796],\n",
            "          [ 0.2453,  0.2111,  0.1768,  ...,  0.2624,  0.2624,  0.2796],\n",
            "          ...,\n",
            "          [ 0.2111,  0.2111,  0.2282,  ..., -0.2684, -0.1657, -0.0801],\n",
            "          [ 0.2111,  0.2111,  0.2282,  ..., -0.1314, -0.0116,  0.0569],\n",
            "          [ 0.2111,  0.2111,  0.2282,  ..., -0.0287,  0.0912,  0.1597]],\n",
            "\n",
            "         [[ 0.2577,  0.2752,  0.3102,  ...,  0.3102,  0.3277,  0.3452],\n",
            "          [ 0.2927,  0.2927,  0.2752,  ...,  0.3102,  0.3277,  0.3452],\n",
            "          [ 0.3102,  0.2752,  0.2402,  ...,  0.3277,  0.3277,  0.3452],\n",
            "          ...,\n",
            "          [ 0.2752,  0.2752,  0.2927,  ..., -0.2150, -0.1099, -0.0224],\n",
            "          [ 0.2752,  0.2752,  0.2927,  ..., -0.0749,  0.0476,  0.1176],\n",
            "          [ 0.2752,  0.2752,  0.2927,  ...,  0.0301,  0.1527,  0.2227]],\n",
            "\n",
            "         [[ 0.2696,  0.2871,  0.3219,  ...,  0.3219,  0.3393,  0.3568],\n",
            "          [ 0.3045,  0.3045,  0.2871,  ...,  0.3219,  0.3393,  0.3568],\n",
            "          [ 0.3219,  0.2871,  0.2522,  ...,  0.3393,  0.3393,  0.3568],\n",
            "          ...,\n",
            "          [ 0.2871,  0.2871,  0.3045,  ..., -0.1835, -0.0790,  0.0082],\n",
            "          [ 0.2871,  0.2871,  0.3045,  ..., -0.0441,  0.0779,  0.1476],\n",
            "          [ 0.2871,  0.2871,  0.3045,  ...,  0.0605,  0.1825,  0.2522]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3481,  0.3309,  0.3481,  ...,  0.5022,  0.4679,  0.4337],\n",
            "          [ 0.3652,  0.3652,  0.3652,  ...,  0.5707,  0.5364,  0.5022],\n",
            "          [ 0.4166,  0.3994,  0.3823,  ...,  0.5878,  0.5536,  0.5193],\n",
            "          ...,\n",
            "          [ 0.7419,  0.7591,  0.6906,  ...,  0.5707,  0.5536,  0.5364],\n",
            "          [ 0.7419,  0.7591,  0.7248,  ...,  0.5878,  0.5707,  0.5536],\n",
            "          [ 0.7248,  0.7762,  0.7591,  ...,  0.6049,  0.5878,  0.5707]],\n",
            "\n",
            "         [[ 0.3277,  0.3102,  0.3277,  ...,  0.5028,  0.4503,  0.4153],\n",
            "          [ 0.3452,  0.3452,  0.3452,  ...,  0.5553,  0.5203,  0.4853],\n",
            "          [ 0.3978,  0.3803,  0.3627,  ...,  0.5728,  0.5378,  0.5028],\n",
            "          ...,\n",
            "          [ 0.7479,  0.7654,  0.6954,  ...,  0.5728,  0.5553,  0.5378],\n",
            "          [ 0.7479,  0.7654,  0.7304,  ...,  0.5903,  0.5728,  0.5553],\n",
            "          [ 0.7304,  0.7829,  0.7654,  ...,  0.6078,  0.5903,  0.5728]],\n",
            "\n",
            "         [[ 0.2871,  0.2696,  0.2871,  ...,  0.5659,  0.5136,  0.4788],\n",
            "          [ 0.3045,  0.3045,  0.3045,  ...,  0.6182,  0.5834,  0.5485],\n",
            "          [ 0.3568,  0.3393,  0.3219,  ...,  0.6356,  0.6008,  0.5659],\n",
            "          ...,\n",
            "          [ 0.7751,  0.7925,  0.7228,  ...,  0.6008,  0.5834,  0.5659],\n",
            "          [ 0.7751,  0.7925,  0.7576,  ...,  0.6182,  0.6008,  0.5834],\n",
            "          [ 0.7576,  0.8099,  0.7925,  ...,  0.6356,  0.6182,  0.6008]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9303,  0.9303,  0.9303,  ...,  0.5193,  0.5364,  0.5536],\n",
            "          [ 0.8618,  0.8789,  0.8961,  ...,  0.5707,  0.5878,  0.5878],\n",
            "          [ 0.7762,  0.8104,  0.8447,  ...,  0.6563,  0.6563,  0.6563],\n",
            "          ...,\n",
            "          [ 0.8961,  0.8789,  0.8618,  ...,  1.1700,  1.1872,  1.2043],\n",
            "          [ 0.8618,  0.8447,  0.8276,  ...,  1.1700,  1.1872,  1.2043],\n",
            "          [ 0.8276,  0.8104,  0.7933,  ...,  1.1700,  1.1872,  1.2043]],\n",
            "\n",
            "         [[ 0.9055,  0.9055,  0.9055,  ...,  0.4853,  0.5028,  0.5203],\n",
            "          [ 0.8354,  0.8529,  0.8704,  ...,  0.5378,  0.5553,  0.5553],\n",
            "          [ 0.7479,  0.7829,  0.8179,  ...,  0.6254,  0.6254,  0.6254],\n",
            "          ...,\n",
            "          [ 0.8704,  0.8529,  0.8354,  ...,  1.1506,  1.1681,  1.1856],\n",
            "          [ 0.8354,  0.8179,  0.8004,  ...,  1.1506,  1.1681,  1.1856],\n",
            "          [ 0.8004,  0.7829,  0.7654,  ...,  1.1506,  1.1681,  1.1856]],\n",
            "\n",
            "         [[ 0.9494,  0.9494,  0.9494,  ...,  0.5311,  0.5485,  0.5659],\n",
            "          [ 0.8797,  0.8971,  0.9145,  ...,  0.5834,  0.6008,  0.6008],\n",
            "          [ 0.7925,  0.8274,  0.8622,  ...,  0.6705,  0.6705,  0.6705],\n",
            "          ...,\n",
            "          [ 0.9145,  0.8971,  0.8797,  ...,  1.1585,  1.1759,  1.1934],\n",
            "          [ 0.8797,  0.8622,  0.8448,  ...,  1.1585,  1.1759,  1.1934],\n",
            "          [ 0.8448,  0.8274,  0.8099,  ...,  1.1585,  1.1759,  1.1934]]]])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iAqa9wXtZ2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c716387-5580-4cc6-c780-5dd05d3df542"
      },
      "source": [
        "print(len(misclassified_list))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkuS08pVtZ2Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "3af4c6b2-7ca8-450a-85af-0cb7afd56f66"
      },
      "source": [
        "for t in misclassified_list:\n",
        "    print(\"t is: \", t.size())\n",
        "    from torchvision import transforms\n",
        "    im = transforms.ToPILImage()(t.reshape(3,224,224)).convert(\"RGB\")\n",
        "    #im = transforms.ToPILImage()(t)\n",
        "    #plt.imshow(trans(trans1(img).convert(\"RGB\")))\n",
        "    display(im)\n",
        "    print(im)\n",
        "    print(im.size)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t is:  torch.Size([100, 3, 224, 224])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-daa52f3b1159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t is: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m#im = transforms.ToPILImage()(t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#plt.imshow(trans(trans1(img).convert(\"RGB\")))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 224, 224]' is invalid for input of size 15052800"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWS7v643tZ2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "d5559264-a014-4cd1-9cd2-cc45e9a72996"
      },
      "source": [
        "count=0\n",
        "\n",
        "for x, y in torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1):\n",
        "#for x,y in validation_dataset:  \n",
        "     \n",
        "    #make a prediction\n",
        "    z = model(x)\n",
        "    #find max \n",
        "    _,yhat = torch.max(z.data, 1)\n",
        "    if  yhat != y:\n",
        "        \n",
        "        from torchvision import transforms\n",
        "        \n",
        "        im = transforms.ToPILImage()(x).convert(\"RGB\")\n",
        "        display(im)\n",
        "        print(im)\n",
        "        print(im.size)\n",
        "        \n",
        "        count += 1\n",
        "    if count >=4:\n",
        "        break"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e0122511cf56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pic should be Tensor or ndarray. Got {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: pic should be Tensor or ndarray. Got <class 'torch.Size'>."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me0dbvo7tZ2h",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/share-notebooks.html\"> CLICK HERE </a> Click here to see how to share your notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJGXSpOhtZ2i",
        "colab_type": "text"
      },
      "source": [
        "<h2>About the Authors:</h2> \n",
        "\n",
        "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMiiE9Y0tZ2j",
        "colab_type": "text"
      },
      "source": [
        "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
      ]
    }
  ]
}